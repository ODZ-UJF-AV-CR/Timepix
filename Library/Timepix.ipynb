{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run /home/sommema4/git/Timepix/Timepix_library/Cluster.ipynb\n",
    "\n",
    "def go_through_files(path, extension):\n",
    "    temp = os.path.join(path, '*.' + extension)\n",
    "    print(temp)\n",
    "    files = glob.glob(temp)\n",
    "    return files\n",
    "\n",
    "def read_clog(filename):\n",
    "    # Opens .clog file, slices data into frames and saves data to a matrix\n",
    "    cluster_list = []\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            if (line.find('Frame') != -1):\n",
    "                frame = line\n",
    "            else:\n",
    "                line = line.replace('[', '').replace(']','').replace(',', '')\n",
    "                words = line.split()\n",
    "                x = list(map(int, words[0::3]))\n",
    "                y = list(map(int, words[1::3]))\n",
    "                energy = list(map(float, words[2::3]))\n",
    "                cluster = list(zip(x, y, energy))\n",
    "                if cluster != []:\n",
    "                    cluster_list.append((frame, cluster))\n",
    "    return cluster_list\n",
    "    \n",
    "def get_properties(timepix):\n",
    "    # Determines the properties of chip (mass and width) based on the manufacture number\n",
    "    if (timepix == \"H08-W0276\" or \"I08-W0276\"):\n",
    "        mass = 2.3008477184E-04\n",
    "        width = 300\n",
    "    elif (timepix == \"C08-W0276\"):\n",
    "        mass = 3.8347461973E-04\n",
    "        width = 500\n",
    "    else:\n",
    "        mass = 0\n",
    "        width = 0\n",
    "    return mass, width\n",
    "\n",
    "def to_dataframe(data, tokens):\n",
    "    dic = {'frame': 0, 'unix': 0, 'shutter': 0, 'volume': 0,\n",
    "           'height': 0, 'size': 0, 'x_max': 0, 'y_max': 0,\n",
    "           'Tx': 0, 'Ty': 0, 'volume_2': 0, 'height_2': 0}\n",
    "    lst = []\n",
    "    for frame, cluster in data:\n",
    "        x, y, energy = list(zip(*cluster))\n",
    "        x = list(x)\n",
    "        y = list(y)\n",
    "        energy = list(energy)\n",
    "        if ('frame' in tokens or 'unix' in tokens or 'shutter' in tokens):\n",
    "            dic['frame'], dic['unix'], dic['shutter'] = frame_to_words(frame)\n",
    "        if ('volume' in tokens or 'height' in tokens or 'size' in tokens or 'x_max' in tokens or 'y_max' in tokens):\n",
    "            dic['volume'], dic['height'], dic['size'], dic['x_max'], dic['y_max'] = get_vhs(x, y, energy)\n",
    "        if ('Tx' in tokens or 'Ty' in tokens):\n",
    "            dic['Tx'], dic['Ty'] = centroid_weighted(x, y, energy)\n",
    "        if ('volume_2' in tokens or 'height_2' in tokens):\n",
    "            dic['volume_2'], dic['height_2'] = hot_pixel_excluded(energy)\n",
    "            \n",
    "        temp = [dic[i] for i in tokens]\n",
    "        lst.append(tuple(temp))\n",
    "    df = pd.DataFrame(lst, columns=tokens)\n",
    "    return df\n",
    "\n",
    "def pixelize(df, x, y):\n",
    "    df_x = df[df['x_max']==x]\n",
    "    pixel = df_x[df_x['y_max']==y]\n",
    "    return pixel\n",
    "\n",
    "def pixelize_to_hdf(df, path, calibration_matrice, distance, bias, attribute):\n",
    "    for i in range(256):\n",
    "        print('Row: ', i)\n",
    "        df_x = df[df['x_max']==i]\n",
    "        directory = os.path.join(path, 'row_' + str(i))\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        for j in range(256):\n",
    "            file = os.path.join(directory, str(i) + 'x' + str(j) + '.h5')\n",
    "            pixel = df_x[df_x['y_max']==j]           \n",
    "            a, b, c, t = get_perpixel_coeffs(i, j, calibration_matrice)\n",
    "            pixel['height_TOT'] = decalibrate_pixel(pixel['height'], a, b, c, t)\n",
    "            save_table_to_hdf(pixel, file, [a, b, c, t], distance, bias, attribute)\n",
    "            \n",
    "def save_table_to_hdf(df, file, calibration, distance, bias, attribute):\n",
    "    [a, b, c, t] = calibration\n",
    "    with h5py.File(file, 'a', libver='latest') as hdf:\n",
    "        if 'A' not in hdf.attrs.keys():\n",
    "            hdf.attrs['A'] = a\n",
    "            hdf.attrs['B'] = b\n",
    "            hdf.attrs['C'] = c\n",
    "            hdf.attrs['T'] = t\n",
    "        \n",
    "        if distance == None:\n",
    "            group = hdf.require_group('undefined_dist_data')\n",
    "        else:\n",
    "            group = hdf.require_group(str(distance))\n",
    "        if attribute == None:\n",
    "            name = str(bias) + '_V'\n",
    "        else:\n",
    "            name = str(bias) + '_V_' + attribute\n",
    "        dset = group.create_dataset(name, data=df)\n",
    "        dset.attrs['BIAS'] = bias\n",
    "        if distance != None:\n",
    "            dset.attrs['DISTANCE'] = distance\n",
    "        if attribute != None:\n",
    "            dset.attrs['ATTRIBUTE'] = attribute\n",
    "\n",
    "def frame_to_words(string):\n",
    "    data = string.split(' ')\n",
    "    frame_i = data[1]\n",
    "    shutter = data[3]\n",
    "    data[2] = data[2].replace(\"(\", \"\")\n",
    "    unix_time = data[2].replace(\",\", \"\")\n",
    "    return frame_i, unix_time, shutter\n",
    "\n",
    "def read_csv(filename):\n",
    "    return pd.read_csv(filename)\n",
    "\n",
    "def perpixel_calibration_matrice(path):\n",
    "    # Save matrice to memory\n",
    "    clog_file = os.path.join(path, 'A.txt')\n",
    "    try:\n",
    "        A = pd.read_csv(clog_file, sep=' ', header=None)\n",
    "    except:\n",
    "        print('Calibration file ' + clog_file + ' could not be found.')\n",
    "    A = np.array(A)\n",
    "    A = A.transpose()\n",
    "    clog_file = os.path.join(path, 'B.txt')\n",
    "    \n",
    "    try:\n",
    "        B = pd.read_csv(clog_file, sep=' ', header=None)\n",
    "    except:\n",
    "        print('Calibration file ' + clog_file + ' could not be found.')\n",
    "    B = np.array(A)\n",
    "    B = A.transpose()\n",
    "    clog_file = os.path.join(path, 'C.txt')\n",
    "    \n",
    "    try:\n",
    "        C = pd.read_csv(clog_file, sep=' ', header=None)\n",
    "    except:\n",
    "        print('Calibration file ' + clog_file + ' could not be found.')\n",
    "    C = np.array(A)\n",
    "    C = A.transpose()\n",
    "    clog_file = os.path.join(path, 'T.txt')\n",
    "    \n",
    "    try:\n",
    "        T = pd.read_csv(clog_file, sep=' ', header=None)\n",
    "    except:\n",
    "        print('Calibration file ' + clog_file + ' could not be found.')\n",
    "    T = np.array(A)\n",
    "    T = A.transpose()\n",
    "    \n",
    "    return [A, B, C, T]\n",
    "\n",
    "def get_perpixel_coeffs(x, y, matrice):\n",
    "    [A, B, C, T] = matrice\n",
    "    a = float(A[x][y])\n",
    "    b = float(B[x][y])\n",
    "    c = float(C[x][y])\n",
    "    t = float(T[x][y])\n",
    "    return a, b, c, t\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "ipython_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
